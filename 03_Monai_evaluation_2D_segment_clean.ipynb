{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aeb709e",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd67f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandAdjustContrastd,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    AsChannelFirstd,\n",
    "    AsChannelLast,\n",
    "    Resized,\n",
    "    RandScaleCropd,\n",
    "    RandRotated,\n",
    "    Rotated,\n",
    "    SaveImage,\n",
    "    ThresholdIntensity,\n",
    "    ThresholdIntensityd,\n",
    "    RandBiasField\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb49be",
   "metadata": {},
   "source": [
    "# Check MONAI configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe0c700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.1\n",
      "Numpy version: 1.20.3\n",
      "Pytorch version: 1.11.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 71ff399a3ea07aef667b23653620a290364095b1\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.12.0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.4\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45e9ae",
   "metadata": {},
   "source": [
    "# Process VGH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c82a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Data folder\n",
    "data_path = \"D:/nycu_deep_learning/SEG_Train_Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35b1bc",
   "metadata": {},
   "source": [
    "## -obtain testing data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fcfcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing files\n",
    "\n",
    "tempdir = data_path + \"Public_Image/\"\n",
    "test_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "tempdir = data_path + \"mask_img/\"\n",
    "test_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n",
    "\n",
    "test_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(test_images[:], test_segs[:131])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e69c02",
   "metadata": {},
   "source": [
    "# Define Transform for image and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4b9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "threshold_value = 0.4\n",
    "cval_value=0.9\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        \n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        #Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        #ThresholdIntensityd(keys=[\"img\"],threshold=threshold_value,above=False,cval=cval_value)\n",
    "        \n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb98f41",
   "metadata": {},
   "source": [
    "# Create Data Loader, Save Output, Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc300b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window inference need to input 1 image in every iteration\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "saver = SaveImage(output_dir=\"./output\", output_ext=\".png\",scale=255,separate_folder=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.DynUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3,3,3,3,3,3),\n",
    "    strides=(1,2,2,2,2,2),\n",
    "    filters  = (36, 64, 128, 256, 512, 1024), #  [32, 64, 128, 256, 512, 1024][: len(strides)]\n",
    "    upsample_kernel_size=(2,2,2,2,2,2), # The values should equal to strides[1:]\n",
    "    res_block=True,\n",
    "    trans_bias=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8fc863",
   "metadata": {},
   "source": [
    "# Load previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebaaf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ecf333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_dict_15.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b4e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(\"Final_model_40_epoches_segmentation2d_dict.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "968247bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image,'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a45dc1",
   "metadata": {},
   "source": [
    "# Run evaluation on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ecc05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path = r'C:\\Users\\chwu\\nycu_deep_learning\\output'\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4e0b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6030cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28328/3233948554.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"img\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"seg\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = test_data[\"img\"].to(device), test_data[\"seg\"].to(device)\n",
    "\n",
    "        # define sliding window size and batch size for windows inference\n",
    "        roi_size = (1696, 928)\n",
    "        sw_batch_size = 2\n",
    "        test_outputs = sliding_window_inference(test_images, roi_size, sw_batch_size, model)\n",
    "\n",
    "        visualize( \n",
    "            image=test_images[0].cpu().permute(1,2,0), \n",
    "            ground_truth_mask=test_labels[0].cpu().permute(1,2,0), \n",
    "            predicted_mask=test_outputs[0].squeeze().cpu().numpy().round()\n",
    "        )   \n",
    "       \n",
    "        test_outputs = [post_trans(i) for i in decollate_batch(test_outputs)]\n",
    "        test_labels = [post_trans(i) for i in decollate_batch(test_labels)]\n",
    "        \n",
    "        #test_labels = decollate_batch(test_labels)\n",
    "        # compute metric for current iteration\n",
    "        dice_metric(y_pred=test_outputs, y=test_labels)\n",
    "        for test_output in test_outputs:   \n",
    "            image_names = test_data['img_meta_dict']['filename_or_obj'][0].split('\\\\')[4][:-4]\n",
    "            test_output = test_output.permute(0,2,1)\n",
    "            test_output_copy = test_output.cpu().numpy()\n",
    "            cv2.imwrite(image_names+'.png' , (test_output_copy*255).squeeze())\n",
    "#             saver = SaveImage(output_dir=\"./output\", output_postfix = '' ,output_ext=\".png\",scale=255,separate_folder=False)\n",
    "#             saver(test_output*255,meta_data=' ')\n",
    "    # aggregate the final mean dice result    \n",
    "    print(\"evaluation metric:\", dice_metric.aggregate().item())\n",
    "    # reset the status\n",
    "    dice_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16eda3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
