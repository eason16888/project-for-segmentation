{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1463a5",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference, SimpleInferer\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandAdjustContrastd,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    AsChannelFirstd,\n",
    "    AsChannelLast,\n",
    "    Resized,\n",
    "    RandScaleCropd,\n",
    "    RandRotated,\n",
    "    Rotated,\n",
    "    SaveImage,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11156bbd",
   "metadata": {},
   "source": [
    "# Check MONAI configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb46bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aba2a0",
   "metadata": {},
   "source": [
    "# Process VGH Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Data folder\n",
    "data_path = \"/Workspace/data/SEG_Train_Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa770735",
   "metadata": {},
   "source": [
    "## -obtain train data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3507bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train files\n",
    "tempdir = data_path + \"Train_Combine_Images/\"\n",
    "train_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "tempdir = data_path + \"Train_Combine_Masks/\"\n",
    "train_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n",
    "print(f\" {len(train_images)} train_images and {len(train_segs)} train_segs\")\n",
    "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[:], train_segs[:])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22faf400",
   "metadata": {},
   "source": [
    "## -obtain validation data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67248e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation files\n",
    "tempdir = data_path + \"Valid_Images/\"\n",
    "valid_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "tempdir = data_path + \"Valid_Masks/\"\n",
    "valid_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n",
    "print(f\" {len(valid_images)} valid_images and {len(valid_segs)} valid_segs\")\n",
    "\n",
    "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(valid_images[:], valid_segs[:])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c78d291",
   "metadata": {},
   "source": [
    "# Define Trasform for image and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        #RandScaleCropd(keys=[\"img\", \"seg\"],roi_scale=0.5,max_roi_scale=1.5),\n",
    "        #RandRotated(keys=[\"img\", \"seg\"],range_x=3.14),\n",
    "        RandAdjustContrastd(keys=[\"img\"], prob=0.1, gamma=(0.5, 4.5)),\n",
    "        #RandCropByPosNegLabeld(\n",
    "        #    keys=[\"img\", \"seg\"], label_key=\"seg\", spatial_size=[800, 800], pos=1, neg=1, num_samples=4\n",
    "        #),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5),\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=[1600, 800]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=[1696, 928]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1640f",
   "metadata": {},
   "source": [
    "# Check and visualize the transform results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1067c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset, data loader\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2adad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "batch = 4\n",
    "check_loader = DataLoader(check_ds, batch_size=batch, num_workers=12, collate_fn=list_data_collate)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(\"visualize\",(16,64))\n",
    "for i in range(batch):\n",
    "    plt.subplot(8,2,2*i+1)    \n",
    "    plt.imshow(check_data[\"img\"][i].permute(1,2,0))\n",
    "    plt.subplot(8,2,2*i+2)\n",
    "    plt.imshow(check_data[\"seg\"][i].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0a0a2",
   "metadata": {},
   "source": [
    "# Create DataLoader for train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69cd715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281e7f0",
   "metadata": {},
   "source": [
    "# Define metric and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943196cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_trans_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578cf36",
   "metadata": {},
   "source": [
    "# Built Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.DynUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3,3,3,3),\n",
    "    strides=(1,2,2,2),\n",
    "    upsample_kernel_size=(2,2,2,2),\n",
    "    res_block=True,\n",
    "    trans_bias=True,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d576f5a",
   "metadata": {},
   "source": [
    "# Do you want to load previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(\"Dice_55_best_metric_model_segmentation2d_dict.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0cb83f",
   "metadata": {},
   "source": [
    "# Create Visualize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17524711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16060c73",
   "metadata": {},
   "source": [
    "# Define training parameters and Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735ea32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### start a typical PyTorch training\n",
    "total_epochs = 300\n",
    "val_interval = 1\n",
    "best_metric = 0\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(total_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{total_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        outputs=[post_trans(i) for i in decollate_batch(outputs)]\n",
    "        labels=[post_trans_label(i) for i in decollate_batch(labels)] \n",
    "        dice_metric(y_pred=outputs, y=labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        # print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    dice_metric.reset()\n",
    "    #print(\"current training dice score: {:.4f} \".format(metric))\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    local_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    print(f\"{local_time} epoch {epoch + 1} average loss: {epoch_loss:.4f} dice score:{metric}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            show_val = True\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                roi_size = (1600, 800)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model) \n",
    "                \n",
    "                #if show_val:\n",
    "                #    visualize( \n",
    "                #        image=val_images[0].cpu().permute(1,2,0), \n",
    "                #        ground_truth_mask=val_labels[0].cpu().permute(1,2,0), \n",
    "                #        predicted_mask=val_outputs[0].cpu().permute(1,2,0)\n",
    "                #    )        \n",
    "                \n",
    "                \n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n",
    "                val_labels = [post_trans_label(i) for i in decollate_batch(val_labels)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                if show_val:\n",
    "                    visualize( \n",
    "                        image=val_images[0].cpu().permute(1,2,0), \n",
    "                        ground_truth_mask=val_labels[0].cpu().permute(1,2,0), \n",
    "                        predicted_mask=val_outputs[0].cpu().permute(1,2,0)\n",
    "                    )                                      \n",
    "                \n",
    "                show_val = False\n",
    "                \n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()            \n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model_segmentation2d_dict.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current val mean dice score: {:.4f} best val mean dice score: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice score\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "            \n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), \"Final_model_40_epoches_segmentation2d_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a70e3",
   "metadata": {},
   "source": [
    "## -obtain testing data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Data folder\n",
    "data_path = \"D:/nycu_deep_learning/SEG_Train_Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing files\n",
    "tempdir = data_path + \"Public_Image/\"\n",
    "test_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "#tempdir = data_path + \"Valid_Masks/\"\n",
    "#test_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n",
    "\n",
    "#print(f\" {len(test_images)} test_images and {len(test_segs)} test_segs\")\n",
    "print(f\" {len(test_images)} test_images\")\n",
    "\n",
    "test_files = [{\"img\": img} for img in zip(test_images[:])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622d613",
   "metadata": {},
   "source": [
    "# Define Transform for image and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "#test_transforms = Compose(\n",
    "#    [\n",
    "#        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "#        \n",
    "#        AddChanneld(keys=[\"seg\"]),        \n",
    "#        AsChannelFirstd(keys=[\"img\"]),\n",
    "\n",
    "#        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "#        #Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n",
    "#        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "#    ]\n",
    "#)\n",
    "#test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a767576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\"]),\n",
    "        \n",
    "        #Rotated(keys=[\"img\"], angle=90),\n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "\n",
    "        ScaleIntensityd(keys=[\"img\"]),\n",
    "        #Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\"]),\n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)\n",
    "\n",
    "\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15a889",
   "metadata": {},
   "source": [
    "# Save IM(images) GT(ground-truths) PD(predictions) in the /output/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79223b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n",
    "saverPD = SaveImage(output_dir=\"./output\", output_ext=\".png\", output_postfix=\"PD\",scale=255,separate_folder=False)\n",
    "#saverGT = SaveImage(output_dir=\"./output\", output_ext=\".png\", output_postfix=\"GT\",scale=255,separate_folder=False)\n",
    "#saverIM = SaveImage(output_dir=\"./output\", output_ext=\".png\", output_postfix=\"IM\",scale=255,separate_folder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74577973",
   "metadata": {},
   "source": [
    "# Load another model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a09d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_dict.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302c6a5",
   "metadata": {},
   "source": [
    "# Inference on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path = r'C:\\Users\\chwu\\nycu_deep_learning\\output'\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5802cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c4078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images= test_data[\"img\"].to(device)\n",
    "        # define sliding window size and batch size for windows inference\n",
    "        roi_size = (1696, 928)\n",
    "        sw_batch_size = 2\n",
    "        test_outputs = sliding_window_inference(test_images, roi_size, sw_batch_size, model)\n",
    "\n",
    "        visualize( \n",
    "            image=test_images[0].cpu().permute(1,2,0),             \n",
    "            predicted_mask=test_outputs[0].squeeze().cpu().numpy().round()\n",
    "        )                   \n",
    "        #saverIM(test_images[0].cpu())        \n",
    "        saverPD(test_outputs[0].cpu())\n",
    "        \n",
    "        test_outputs = [post_trans(i) for i in decollate_batch(test_outputs)]        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e949d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original code (backup)\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = test_data[\"img\"].to(device), test_data[\"seg\"].to(device)\n",
    "        # define sliding window size and batch size for windows inference\n",
    "        roi_size = (800, 800)\n",
    "        sw_batch_size = 4\n",
    "        test_outputs = sliding_window_inference(test_images, roi_size, sw_batch_size, model)\n",
    "\n",
    "        visualize( \n",
    "            image=test_images[0].cpu().permute(1,2,0), \n",
    "            ground_truth_mask=test_labels[0].cpu().permute(1,2,0), \n",
    "            predicted_mask=test_outputs[0].squeeze().cpu().numpy().round()\n",
    "        )           \n",
    "        saverGT(test_labels[0].cpu())\n",
    "        saverIM(test_images[0].cpu())        \n",
    "        saverPD(test_outputs[0].cpu())\n",
    "        \n",
    "        test_outputs = [p(i) for i in decollate_batch(test_outputs)]\n",
    "        test_labels = [post_trans(i) for i in decollate_batch(test_labels)]\n",
    "        \n",
    "        \n",
    "                \n",
    "        # compute metric for current iteration\n",
    "        dice_metric(y_pred=test_outputs, y=test_labels)\n",
    "        #for test_output in test_outputs:            \n",
    "        #    saver(test_output*255)\n",
    "    # aggregate the final mean dice result    \n",
    "    print(\"evaluation metric:\", dice_metric.aggregate().item())\n",
    "    # reset the status\n",
    "    dice_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a44a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
