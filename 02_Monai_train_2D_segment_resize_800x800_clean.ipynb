{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bmP6fhZeKbV",
   "metadata": {
    "id": "6bmP6fhZeKbV"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "_b_GBboheKbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7892,
     "status": "ok",
     "timestamp": 1653285346129,
     "user": {
      "displayName": "林奕勳",
      "userId": "09453097102148012125"
     },
     "user_tz": -480
    },
    "id": "_b_GBboheKbc",
    "outputId": "128d63b8-e70e-40d3-e234-113536ffee8d"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import torchvision\n",
    "import timm\n",
    "import mmcv\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import  matplotlib.pyplot as plt\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference, SimpleInferer\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandAdjustContrastd,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    AsChannelFirstd,\n",
    "    AsChannelLast,\n",
    "    Resized,\n",
    "    RandScaleCropd,\n",
    "    RandRotated,\n",
    "    Rotated,\n",
    "    SaveImage,\n",
    "    ThresholdIntensity,\n",
    "    RandBiasField,\n",
    "    ThresholdIntensityd\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZtoiWi_ZeKbf",
   "metadata": {
    "id": "ZtoiWi_ZeKbf"
   },
   "source": [
    "# Check MONAI configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mvSO44yUeKbg",
   "metadata": {
    "id": "mvSO44yUeKbg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.1\n",
      "Numpy version: 1.20.3\n",
      "Pytorch version: 1.11.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 71ff399a3ea07aef667b23653620a290364095b1\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.12.0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.4\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pI84LR46eKbg",
   "metadata": {
    "id": "pI84LR46eKbg"
   },
   "source": [
    "# Process VGH Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Ltt6wOo1eKbh",
   "metadata": {
    "id": "Ltt6wOo1eKbh"
   },
   "outputs": [],
   "source": [
    "# Set the Data folder\n",
    "data_path = \"D:/nycu_deep_learning/SEG_Train_Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spBFpr5UeKbi",
   "metadata": {
    "id": "spBFpr5UeKbi"
   },
   "source": [
    "## -obtain train data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "jDCQwC0PeKbk",
   "metadata": {
    "id": "jDCQwC0PeKbk"
   },
   "outputs": [],
   "source": [
    "# Load train files\n",
    "tempdir = data_path + \"Train_Images/\"\n",
    "train_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "tempdir = data_path + \"mask_img/\"\n",
    "train_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rVy96Kronl7o",
   "metadata": {
    "id": "rVy96Kronl7o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 926 train_images and 926 train_segs\n",
      " 127 valid_images and 127 valid_segs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_images , valid_images , train_segs , valid_segs =  train_test_split(train_images,train_segs, train_size=0.88,random_state=2)\n",
    "\n",
    "print(f\" {len(train_images)} train_images and {len(train_segs)} train_segs\")\n",
    "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[:], train_segs[:])]\n",
    "\n",
    "print(f\" {len(valid_images)} valid_images and {len(valid_segs)} valid_segs\")\n",
    "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(valid_images[:], valid_segs[:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jO_bkfdseKbn",
   "metadata": {
    "id": "jO_bkfdseKbn"
   },
   "source": [
    "# Define Trasform for image and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "t_7kzRt6eKbn",
   "metadata": {
    "id": "t_7kzRt6eKbn"
   },
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "threshold_value = 0.1\n",
    "cval_value=0.2\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        RandScaleCropd(keys=[\"img\", \"seg\"],roi_scale=0.5,max_roi_scale=1.5),\n",
    "        RandRotated(keys=[\"img\", \"seg\"],range_x=3.14),\n",
    "        RandAdjustContrastd(keys=[\"img\"], prob=0.1, gamma=(0.5, 4.5)),\n",
    "        #RandCropByPosNegLabeld(\n",
    "        #    keys=[\"img\", \"seg\"], label_key=\"seg\", spatial_size=[800, 800], pos=1, neg=1, num_samples=4\n",
    "        #),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5),\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=[1600, 800]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        #ThresholdIntensityd(keys=[\"img\"],threshold=threshold_value,above=False,cval=cval_value)\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=[1696, 928]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        #ThresholdIntensityd(keys=[\"img\"],threshold=threshold_value,above=False,cval=cval_value)        \n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sX1iiGaZeKbo",
   "metadata": {
    "id": "sX1iiGaZeKbo"
   },
   "source": [
    "# Check and visualize the transform results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pD2QVh59eKbp",
   "metadata": {
    "id": "pD2QVh59eKbp"
   },
   "outputs": [],
   "source": [
    "# # define dataset, data loader\n",
    "# check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "u888QrDpeKbp",
   "metadata": {
    "id": "u888QrDpeKbp"
   },
   "outputs": [],
   "source": [
    "# # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "# batch = 4\n",
    "# check_loader = DataLoader(check_ds, batch_size=batch, num_workers=12, collate_fn=list_data_collate)\n",
    "# check_data = monai.utils.misc.first(check_loader)\n",
    "# print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(\"visualize\",(16,64))\n",
    "# for i in range(batch):\n",
    "#     plt.subplot(8,2,2*i+1)    \n",
    "#     plt.imshow(check_data[\"img\"][i].permute(1,2,0))\n",
    "#     plt.subplot(8,2,2*i+2)\n",
    "#     plt.imshow(check_data[\"seg\"][i].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mwXMxNoJeKbq",
   "metadata": {
    "id": "mwXMxNoJeKbq"
   },
   "source": [
    "# Create DataLoader for train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "V-gA8iM1eKbq",
   "metadata": {
    "id": "V-gA8iM1eKbq"
   },
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kpJiBbVFeKbr",
   "metadata": {
    "id": "kpJiBbVFeKbr"
   },
   "source": [
    "# Define metric and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ZVAmVBqYeKbr",
   "metadata": {
    "id": "ZVAmVBqYeKbr"
   },
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_trans_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UN2G080feKbr",
   "metadata": {
    "id": "UN2G080feKbr"
   },
   "source": [
    "# Built Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ZL2ZrZeleKbs",
   "metadata": {
    "id": "ZL2ZrZeleKbs"
   },
   "outputs": [],
   "source": [
    "# create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.DynUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3,3,3,3,3,3),\n",
    "    strides=(1,2,2,2,2,2),\n",
    "    filters  = (36, 64, 128, 256, 512, 1024), #  [32, 64, 128, 256, 512, 1024][: len(strides)]\n",
    "    upsample_kernel_size=(2,2,2,2,2,2), # The values should equal to strides[1:]\n",
    "    res_block=True,\n",
    "    trans_bias=True,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "#loss_function = monai.losses.DiceLoss(sigmoid=True,squared_pred =False,jaccard =False)  \n",
    "loss_function = monai.losses.DiceFocalLoss(include_background=True,sigmoid=True,squared_pred =True,lambda_dice=1.,lambda_focal=1.,gamma=5)\n",
    "#loss_function = monai.losses.DiceCELoss(sigmoid=True,lambda_dice=1.0,lambda_ce=1.0)\n",
    "#loss_function = monai.losses.GeneralizedDiceLoss(include_background=True,sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 5e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max',patience=8,factor=0.5,min_lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9237d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ZSB_F9CDeKbw",
   "metadata": {
    "id": "ZSB_F9CDeKbw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_dict_17.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X1euFEq9eKbt",
   "metadata": {
    "id": "X1euFEq9eKbt"
   },
   "source": [
    "# Create Visualize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sSP4pFHLeKbt",
   "metadata": {
    "id": "sSP4pFHLeKbt"
   },
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image,'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ygjOf7HLeKbu",
   "metadata": {
    "id": "ygjOf7HLeKbu"
   },
   "source": [
    "# Define training parameters and Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feff2e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 15:08:51 epoch 1 average loss: 0.1433 dice score:0.8781594038009644\n",
      "epoch: 1 learning rate: 0.005\n",
      "saved new best metric model\n",
      "current epoch: 1 current val mean dice score: 0.8606 best val mean dice score: 0.8606 at epoch 1\n",
      "----------\n",
      "epoch 2/250\n",
      "2022-05-30 15:18:44 epoch 2 average loss: 0.1367 dice score:0.8825605511665344\n",
      "epoch: 2 learning rate: 0.005\n",
      "saved new best metric model\n",
      "current epoch: 2 current val mean dice score: 0.8625 best val mean dice score: 0.8625 at epoch 2\n",
      "----------\n",
      "epoch 3/250\n",
      "2022-05-30 15:24:07 epoch 3 average loss: 0.1332 dice score:0.8770321011543274\n",
      "epoch: 3 learning rate: 0.005\n",
      "current epoch: 3 current val mean dice score: 0.8562 best val mean dice score: 0.8625 at epoch 2\n",
      "----------\n",
      "epoch 4/250\n",
      "2022-05-30 15:29:30 epoch 4 average loss: 0.1281 dice score:0.8772559762001038\n",
      "epoch: 4 learning rate: 0.005\n",
      "saved new best metric model\n",
      "current epoch: 4 current val mean dice score: 0.8627 best val mean dice score: 0.8627 at epoch 4\n",
      "----------\n",
      "epoch 5/250\n",
      "2022-05-30 15:34:52 epoch 5 average loss: 0.1376 dice score:0.8828589916229248\n",
      "epoch: 5 learning rate: 0.005\n",
      "current epoch: 5 current val mean dice score: 0.8326 best val mean dice score: 0.8627 at epoch 4\n",
      "----------\n",
      "epoch 6/250\n",
      "2022-05-30 15:40:15 epoch 6 average loss: 0.1407 dice score:0.8781528472900391\n",
      "epoch: 6 learning rate: 0.005\n",
      "saved new best metric model\n",
      "current epoch: 6 current val mean dice score: 0.8674 best val mean dice score: 0.8674 at epoch 6\n",
      "----------\n",
      "epoch 7/250\n",
      "2022-05-30 15:45:38 epoch 7 average loss: 0.1348 dice score:0.8814848065376282\n",
      "epoch: 7 learning rate: 0.005\n",
      "saved new best metric model\n",
      "current epoch: 7 current val mean dice score: 0.8749 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 8/250\n",
      "2022-05-30 15:51:01 epoch 8 average loss: 0.1319 dice score:0.8864163160324097\n",
      "epoch: 8 learning rate: 0.005\n",
      "current epoch: 8 current val mean dice score: 0.8632 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 9/250\n",
      "2022-05-30 15:56:29 epoch 9 average loss: 0.1568 dice score:0.8647562861442566\n",
      "epoch: 9 learning rate: 0.005\n",
      "current epoch: 9 current val mean dice score: 0.8595 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 10/250\n",
      "2022-05-30 16:01:52 epoch 10 average loss: 0.1177 dice score:0.8893234729766846\n",
      "epoch: 10 learning rate: 0.005\n",
      "current epoch: 10 current val mean dice score: 0.8625 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 11/250\n",
      "2022-05-30 16:07:16 epoch 11 average loss: 0.1306 dice score:0.8824164867401123\n",
      "epoch: 11 learning rate: 0.005\n",
      "current epoch: 11 current val mean dice score: 0.8688 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 12/250\n",
      "2022-05-30 16:12:36 epoch 12 average loss: 0.1334 dice score:0.8814916014671326\n",
      "epoch: 12 learning rate: 0.005\n",
      "current epoch: 12 current val mean dice score: 0.8729 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 13/250\n",
      "2022-05-30 16:17:56 epoch 13 average loss: 0.1340 dice score:0.878569483757019\n",
      "epoch: 13 learning rate: 0.005\n",
      "current epoch: 13 current val mean dice score: 0.8632 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 14/250\n",
      "2022-05-30 16:23:16 epoch 14 average loss: 0.1426 dice score:0.8776806592941284\n",
      "epoch: 14 learning rate: 0.005\n",
      "current epoch: 14 current val mean dice score: 0.8650 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 15/250\n",
      "2022-05-30 16:28:35 epoch 15 average loss: 0.1330 dice score:0.8778153657913208\n",
      "epoch: 15 learning rate: 0.005\n",
      "current epoch: 15 current val mean dice score: 0.8660 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 16/250\n",
      "2022-05-30 16:33:55 epoch 16 average loss: 0.1331 dice score:0.8842053413391113\n",
      "epoch: 16 learning rate: 0.0025\n",
      "current epoch: 16 current val mean dice score: 0.8628 best val mean dice score: 0.8749 at epoch 7\n",
      "----------\n",
      "epoch 17/250\n",
      "2022-05-30 16:39:18 epoch 17 average loss: 0.1255 dice score:0.8878396153450012\n",
      "epoch: 17 learning rate: 0.0025\n",
      "saved new best metric model\n",
      "current epoch: 17 current val mean dice score: 0.8804 best val mean dice score: 0.8804 at epoch 17\n",
      "----------\n",
      "epoch 18/250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12404/2238483138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mepoch_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### start a typical PyTorch training\n",
    "total_epochs = 250\n",
    "val_interval = 1\n",
    "best_metric = 0\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(total_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{total_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        outputs=[post_trans(i) for i in decollate_batch(outputs)]\n",
    "        labels=[post_trans_label(i) for i in decollate_batch(labels)] \n",
    "        dice_metric(y_pred=outputs, y=labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        # print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    dice_metric.reset()\n",
    "    #print(\"current training dice score: {:.4f} \".format(metric))\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    local_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    print(f\"{local_time} epoch {epoch + 1} average loss: {epoch_loss:.4f} dice score:{metric}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            show_val = False\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                      \n",
    "        \n",
    "                roi_size = (1600, 800)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)       \n",
    "                \n",
    "                \n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n",
    "                val_labels = [post_trans_label(i) for i in decollate_batch(val_labels)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                if show_val:\n",
    "                    visualize( \n",
    "                        image=val_images[0].cpu().permute(1,2,0), \n",
    "                        ground_truth_mask=val_labels[0].cpu().permute(1,2,0), \n",
    "                        predicted_mask=val_outputs[0].cpu().permute(1,2,0)\n",
    "                    )                                      \n",
    "                \n",
    "                show_val = False\n",
    "                \n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            scheduler.step(metric)\n",
    "            print('epoch:',epoch+1, 'learning rate:',optimizer.param_groups[0]['lr'])\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()            \n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model_segmentation2d_dict.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current val mean dice score: {:.4f} best val mean dice score: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice score\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "            \n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()\n",
    "\n",
    "torch.save(model.state_dict(), \"Final_model_40_epoches_segmentation2d_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0977edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_Monai_train_2D_segment_resize_800x800_clean.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
